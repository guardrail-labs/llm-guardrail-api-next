apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-guardrail-core
spec:
  replicas: 2
  selector:
    matchLabels: { app: llm-guardrail-core }
  template:
    metadata:
      labels: { app: llm-guardrail-core }
    spec:
      securityContext:
        runAsUser: 65532
        runAsGroup: 65532
        fsGroup: 65532
      containers:
        - name: api
          image: ghcr.io/org/llm-guardrail-api-next:1.0.0
          ports: [{ containerPort: 8000 }]
          args: ["uvicorn","app.main:app","--host","0.0.0.0","--port","8000"]
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            capabilities: { drop: ["ALL"] }
          volumeMounts:
            - name: tmp
              mountPath: /tmp
          readinessProbe:
            httpGet: { path: /healthz, port: 8000 }
          livenessProbe:
            httpGet: { path: /healthz, port: 8000 }
      volumes:
        - name: tmp
          emptyDir: { medium: Memory, sizeLimit: "64Mi" }
