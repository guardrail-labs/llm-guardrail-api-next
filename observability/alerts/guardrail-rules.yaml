groups:
  - name: guardrail-api.rules
    interval: 30s
    rules:
      # Service up check (keep if your Prometheus job label matches)
      - alert: GuardrailRouteDown
        expr: up{job="guardrail"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Guardrail target is down"
          description: "Prometheus cannot scrape the Guardrail API target for >2m."

      # Latency SLO breach (p95 in ms)
      - alert: GuardrailLatencyP95Breached
        expr: 1000 * histogram_quantile(0.95, sum by (le) (rate(guardrail_latency_seconds_bucket[5m]))) > 300
        for: 10m
        labels:
          severity: high
        annotations:
          summary: "Guardrail p95 latency > 300ms"
          description: "Sustained p95 latency breach for 10m."

      # High deny rate (watch for unexpected policy aggressiveness)
      - alert: GuardrailBlockRateHigh
        expr: (sum(rate(guardrail_decisions_total{family="deny"}[5m])) / sum(rate(guardrail_decisions_total[5m]))) > 0.5
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "Guardrail deny rate > 50%"
          description: "More than half of decisions are denies over 15m. Investigate policy/regression or traffic quality."

      - alert: GuardrailServerErrorsHigh
        expr: sum(rate(guardrail_http_status_total{status=~"5.."}[5m])) > 1
        for: 10m
        labels:
          severity: high
        annotations:
          summary: "Guardrail 5xx elevated"
          description: "5xx rate exceeded 1 req/s for 10 minutes."

      - alert: GuardrailThrottlingElevated
        expr: sum(rate(guardrail_http_status_total{status="429"}[5m])) > 2
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Guardrail 429 elevated"
          description: "429 rate sustained >2 req/s for 10 minutes."

  - name: guardrail-webhooks
    interval: 1m
    rules:
      - alert: GuardrailWebhookFailureRateHigh
        expr: |
          sum(rate(guardrail_webhook_deliveries_total{outcome!="sent"}[15m]))
            /
          sum(rate(guardrail_webhook_deliveries_total[15m])) > 0.2
        for: 10m
        labels:
          severity: warning
          team: guardrail
          service: guardrail-api
        annotations:
          summary: "Guardrail webhooks high failure rate"
          description: |
            Failure ratio > 20% over 15m.
            Investigate receiver availability, secrets, allowlist, or TLS settings.
            Ratio = (non-sent outcomes) / (all deliveries).

  - name: guardrail-webhooks-dlq
    interval: 1m
    rules:
      - alert: GuardrailWebhookDLQBacklog
        expr: guardrail_webhook_dlq_length > 0
        for: 10m
        labels:
          severity: warning
          team: guardrail
          service: guardrail-api
        annotations:
          summary: "Guardrail webhook DLQ backlog > 0"
          description: "DLQ has items for 10m+. Investigate receiver availability and consider replay."

      - alert: GuardrailWebhookDLQGrowing
        expr: delta(guardrail_webhook_dlq_length[15m]) > 0
        for: 10m
        labels:
          severity: critical
          team: guardrail
          service: guardrail-api
        annotations:
          summary: "Guardrail webhook DLQ is growing"
          description: "DLQ length increased over the last 15m. Receiver may be unhealthy or misconfigured."
